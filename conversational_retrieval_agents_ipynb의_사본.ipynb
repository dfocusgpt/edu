{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "839f3c76",
      "metadata": {
        "id": "839f3c76"
      },
      "source": [
        "# Using agents\n",
        "\n",
        "This is an agent specifically optimized for doing retrieval when necessary and also holding a conversation.\n",
        "\n",
        "To start, we will set up the retriever we want to use, and then turn it into a retriever tool. Next, we will use the high level constructor for this type of agent. Finally, we will walk through how to construct a conversational retrieval agent from components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "756e6cc8-e268-4831-b707-b56537e405f7",
      "metadata": {
        "id": "756e6cc8-e268-4831-b707-b56537e405f7",
        "outputId": "42ae8ea1-eab9-43b0-98a7-0f7810e309a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc66a262",
      "metadata": {
        "id": "dc66a262"
      },
      "source": [
        "## The Retriever\n",
        "\n",
        "To start, we need a retriever to use! The code here is mostly just example code. Feel free to use your own retriever and skip to the section on creating a retriever tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22533f46",
      "metadata": {
        "id": "22533f46"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"state_of_the_union.txt\")\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqUzk8bmeiHa",
        "outputId": "ec8d7e44-af11-48ad-94ee-43f0ac4e131a"
      },
      "id": "HqUzk8bmeiHa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"ㅍㅍㅍㅍㅍㅍㅍㅍㅍㅍㅍㅍ\""
      ],
      "metadata": {
        "id": "5BNapevvfzEn"
      },
      "id": "5BNapevvfzEn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c252c7e9",
      "metadata": {
        "id": "c252c7e9"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = FAISS.from_documents(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b8a404f",
      "metadata": {
        "id": "5b8a404f"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cd528f5",
      "metadata": {
        "id": "9cd528f5"
      },
      "source": [
        "## Retriever Tool\n",
        "\n",
        "Now we need to create a tool for our retriever. The main things we need to pass in are a name for the retriever as well as a description. These will both be used by the language model, so they should be informative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfbd92a2",
      "metadata": {
        "id": "dfbd92a2"
      },
      "outputs": [],
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"search_state_of_union\",\n",
        "    \"Searches and returns excerpts from the 2022 State of the Union.\",\n",
        ")\n",
        "tools = [tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d9b7210",
      "metadata": {
        "id": "6d9b7210"
      },
      "source": [
        "## Agent Constructor\n",
        "\n",
        "Here, we will use the high level `create_openai_tools_agent` API to construct the agent.\n",
        "\n",
        "Notice that beside the list of tools, the only thing we need to pass in is a language model to use.\n",
        "Under the hood, this agent is using the OpenAI tool-calling capabilities, so we need to use a ChatOpenAI model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd147eb",
      "metadata": {
        "id": "0cd147eb",
        "outputId": "982b8a66-31de-4728-d531-0b927afe676a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
              " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "prompt.messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fa4661b",
      "metadata": {
        "id": "9fa4661b"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da2ad764",
      "metadata": {
        "id": "da2ad764"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ee7677",
      "metadata": {
        "id": "85ee7677"
      },
      "source": [
        "We can now try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03059322",
      "metadata": {
        "id": "03059322"
      },
      "outputs": [],
      "source": [
        "result = agent_executor.invoke({\"input\": \"hi, im bob\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33073ff0",
      "metadata": {
        "id": "33073ff0",
        "outputId": "6e58ffdf-db7c-4ed9-b1aa-9c5907b2ce8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Bob! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "result[\"output\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e258ade",
      "metadata": {
        "id": "8e258ade"
      },
      "source": [
        "Notice that it now does retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd17d67",
      "metadata": {
        "id": "6cd17d67"
      },
      "outputs": [],
      "source": [
        "result = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"what did the president say about ketanji brown jackson in the most recent state of the union?\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c51de037",
      "metadata": {
        "id": "c51de037",
        "outputId": "0fb81802-ebb3-41c7-dd18-46ab9123a75a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the most recent state of the union, the President mentioned Kentaji Brown Jackson. The President nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to serve on the United States Supreme Court. The President described Judge Ketanji Brown Jackson as one of our nation's top legal minds who will continue Justice Breyer's legacy of excellence.\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"output\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3bad540",
      "metadata": {
        "id": "d3bad540"
      },
      "source": [
        "Notice that the follow up question asks about information previously retrieved, so no need to do another retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "527ea5fd",
      "metadata": {
        "id": "527ea5fd"
      },
      "outputs": [],
      "source": [
        "result = agent_executor.invoke(\n",
        "    {\"input\": \"how long ago did the president nominate ketanji brown jackson?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a34d20fd",
      "metadata": {
        "id": "a34d20fd",
        "outputId": "6e039b84-938d-4ca4-bae0-072e49859c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'President Biden nominated Ketanji Brown Jackson 4 days ago.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "result[\"output\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51af2123-f63d-429a-aa58-fe24e3ce22a1",
      "metadata": {
        "id": "51af2123-f63d-429a-aa58-fe24e3ce22a1"
      },
      "source": [
        "For more on how to use agents with retrievers and other tools, head to the [Agents](/docs/modules/agents) section."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent_executor.invoke(\n",
        "    {\"input\": \"한국 대통령은 누구지?\"}\n",
        ")\n",
        "result[\"output\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BaMF28figtLX",
        "outputId": "b413965e-6d49-4d80-9c26-0161b1799b71"
      },
      "id": "BaMF28figtLX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'한국 대통령은 문재인 대통령입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada378d6-0616-4f61-923c-f5c1fbeb04a2",
      "metadata": {
        "id": "ada378d6-0616-4f61-923c-f5c1fbeb04a2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "poetry-venv",
      "language": "python",
      "name": "poetry-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}